{% extends "base.html" %}

{% block meta %}
<meta name="description" content="Today's top AI papers">
<link rel="canonical" href="https://researchdaily.pages.dev/" />
{% endblock meta %}
{% block segment %}
<h2 class="displayTitle">
  Today's top AI papers
</h2>
<div class="bloggrid">
  <div class="w-layout-grid gridlayout">
    <a href="{{ get_url(path='@/blog/pipefill-gpu-utilization-llm-training.md') }}" class="clickDisp">
    <div class="blogdisplay"><img src="/pipefill-gpu-utilization-llm-training.png" loading="lazy" alt="" class="blogcoverimage">
      <h2 class="blogtitle">PipeFill: Using GPUs During Bubbles in Pipeline-Parallel LLM Training</h2>
      <h3 class="blogdate">October 21, 2024</h3>
      <h3 class="blogpapertags">LLM Training, Pipeline Parallelism, GPU Utilization, GPU Efficiency</h3>
      <p class="blogbriefdescp">This paper discusses the inefficiency of GPU utilization in large-scale deep neural network training due to pipeline bubbles.</p>
    </div>
    </a>

    <a href="{{ get_url(path='@/blog/moral-turing-test-human-llm-alignment.md') }}" class="clickDisp">
      <div class="blogdisplay"><img src="/moral-turing-test-human-llm-alignment.png" loading="lazy" alt="" class="blogcoverimage">
        <h2 class="blogtitle">The Moral Turing Test: Evaluating Human-LLM Alignment in Moral Decision-Making</h2>
        <h3 class="blogdate">October 21, 2024</h3>
        <h3 class="blogpapertags">Moral Decision-Making, Human-LLM Alignment, Human-AI Bias</h3>
        <p class="blogbriefdescp">This research paper investigates the alignment between human moral judgments and those generated by Large Language Models (LLMs), specifically the GPT-3.5 family.</p>
      </div>
    </a>
    
  </div>
</div>
{% endblock segment%}