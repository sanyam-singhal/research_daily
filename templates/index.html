
{% extends "base.html" %}

{% block meta %}
<meta name="description" content="Read today's top AI papers. Never miss out on the latest AI research updates.">
<meta property="og:title" content="Research Daily: Top AI papers of the day" />
<meta property="og:description" content="Read today's top AI papers. Never miss out on the latest AI research updates." />
<meta property="og:image" content="https://researchdaily.blog/dAIly.png" />
<meta property="og:url" content="https://researchdaily.blog/" />
<meta property="og:type" content="website" />

<link rel="canonical" href="https://researchdaily.blog/" />
{% endblock meta %}

{% block segment %}
    <h2 class="displayTitle">
    Today's top AI papers
    </h2>
    <div class="bloggrid">
    <div class="w-layout-grid gridlayout">
    <a href="{{ get_url(path='@/blog/verify-neural-cbf-with-bounds.md') }}" class="clickDisp">

        <div class="blogdisplay"><img src="/verify-neural-cbf-with-bounds.png" loading="lazy" alt="Diagram of neural CBF verification pipeline using symbolic bound propagation." class="blogcoverimage">
            <h2 class="blogtitle">Verification of Neural Control Barrier Functions with Symbolic Derivative Bounds Propagation</h2>
            <h3 class="blogdate">October 23, 2024</h3>
            <h3 class="blogpapertags">Neural CBFs, Safety Verification, Robotics, Control Systems</h3>
            <p class="blogbriefdescp">Novel verification framework for neural CBFs enhancing safety and efficiency in robotics and AI safety. High impact.</p>
        </div>
        </a>
        <a href="{{ get_url(path='@/blog/steering-llms-using-conceptors.md') }}" class="clickDisp">

        <div class="blogdisplay"><img src="/steering-llms-using-conceptors.png" loading="lazy" alt="Comparison of additive and conceptor steering for LLMs. Conceptors significantly outperform additive vectors." class="blogcoverimage">
            <h2 class="blogtitle">Steering Large Language Models using Conceptors: Improving Addition-Based Activation Engineering</h2>
            <h3 class="blogdate">October 23, 2024</h3>
            <h3 class="blogpapertags">LLM Control, Conceptors, Activation Engineering, AI Safety</h3>
            <p class="blogbriefdescp">Introduces 'conceptors' for precise LLM output control, advancing LLM control and safety.  High impact.</p>
        </div>
        </a>
        <a href="{{ get_url(path='@/blog/llmscan-causal-scan-llm-misbehavior.md') }}" class="clickDisp">

        <div class="blogdisplay"><img src="/llmscan-causal-scan-llm-misbehavior.png" loading="lazy" alt="LLMSCAN: A two-stage process for detecting LLM misbehavior using causality analysis." class="blogcoverimage">
            <h2 class="blogtitle">LLMScan: Causal Scan for LLM Misbehavior Detection</h2>
            <h3 class="blogdate">October 23, 2024</h3>
            <h3 class="blogpapertags">LLM Safety, Causal Analysis, Misbehavior Detection, AI Safety</h3>
            <p class="blogbriefdescp">Novel causal analysis for LLM safety, detecting various misbehaviors.  Comprehensive solution to LLM safety concerns.</p>
        </div>
        </a>
        <a href="{{ get_url(path='@/blog/controlled-low-rank-adaptation-llms.md') }}" class="clickDisp">

        <div class="blogdisplay"><img src="/controlled-low-rank-adaptation-llms.png" loading="lazy" alt="Diagram illustrating Controlled LoRA's (CLoRA) subspace regularization approach for mitigating catastrophic forgetting in LLMs." class="blogcoverimage">
            <h2 class="blogtitle">Controlled Low-Rank Adaptation with Subspace Regularization for Continued Training on Large Language Models</h2>
            <h3 class="blogdate">October 23, 2024</h3>
            <h3 class="blogpapertags">LLM Training, Catastrophic Forgetting, CLoRA, Model Efficiency</h3>
            <p class="blogbriefdescp">Addresses catastrophic forgetting in LLMs. CLoRA improves performance on new and old tasks, impacting LLM training.</p>
        </div>
        </a>
        <a href="{{ get_url(path='@/blog/llm-invented-algorithms-self-improve.md') }}" class="clickDisp">

        <div class="blogdisplay"><img src="/llm-invented-algorithms-self-improve.png" loading="lazy" alt="Diagram showing the Self-Developing framework for LLMs to autonomously generate model-improving algorithms." class="blogcoverimage">
            <h2 class="blogtitle">Can Large Language Models Invent Algorithms to Improve Themselves?</h2>
            <h3 class="blogdate">October 23, 2024</h3>
            <h3 class="blogpapertags">Self-Improving LLMs, Autonomous AI, Algorithm Invention, AI Development</h3>
            <p class="blogbriefdescp">Groundbreaking self-developing framework lets LLMs create self-improvement algorithms, showcasing potential for autonomous AI.</p>
        </div>
        </a>
        
    </div>
    </div>
{% endblock segment %}
